{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Assignment 2 Part 2\n",
    "# Model Assessment \n",
    "# Taiwan credit card default dataset\n",
    "(Source: Taken from https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of data is (30000, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Sept05_BillAmt</th>\n",
       "      <th>Sept05_PayAmt</th>\n",
       "      <th>Aug05_PayAmt</th>\n",
       "      <th>Jul05_PayAmt</th>\n",
       "      <th>Jun05_PayAmt</th>\n",
       "      <th>May05_PayAmt</th>\n",
       "      <th>Apr05_PayAmt</th>\n",
       "      <th>avrg_delay</th>\n",
       "      <th>...</th>\n",
       "      <th>Aug_Pay_Ratio</th>\n",
       "      <th>Missed_payments</th>\n",
       "      <th>SEX_M</th>\n",
       "      <th>EDUCATION_Grad school</th>\n",
       "      <th>EDUCATION_High school</th>\n",
       "      <th>EDUCATION_University</th>\n",
       "      <th>MARRIAGE_Divorced</th>\n",
       "      <th>MARRIAGE_Married</th>\n",
       "      <th>MARRIAGE_Single</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>24</td>\n",
       "      <td>3913</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>26</td>\n",
       "      <td>2682</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>34</td>\n",
       "      <td>29239</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>37</td>\n",
       "      <td>46990</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>57</td>\n",
       "      <td>8617</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  AGE  Sept05_BillAmt  Sept05_PayAmt  Aug05_PayAmt  Jul05_PayAmt  \\\n",
       "ID                                                                              \n",
       "1       20000   24            3913              0           689             0   \n",
       "2      120000   26            2682              0          1000          1000   \n",
       "3       90000   34           29239           1518          1500          1000   \n",
       "4       50000   37           46990           2000          2019          1200   \n",
       "5       50000   57            8617           2000         36681         10000   \n",
       "\n",
       "    Jun05_PayAmt  May05_PayAmt  Apr05_PayAmt  avrg_delay  ...  Aug_Pay_Ratio  \\\n",
       "ID                                                        ...                  \n",
       "1              0             0             0   -0.333333  ...       0.000000   \n",
       "2           1000             0          2000    0.500000  ...       0.000000   \n",
       "3           1000          1000          5000    0.000000  ...       0.108220   \n",
       "4           1100          1069          1000    0.000000  ...       0.041465   \n",
       "5           9000           689           679   -0.333333  ...       0.352734   \n",
       "\n",
       "    Missed_payments  SEX_M  EDUCATION_Grad school  EDUCATION_High school  \\\n",
       "ID                                                                         \n",
       "1                 5      0                      0                      0   \n",
       "2                 2      0                      0                      0   \n",
       "3                 0      0                      0                      0   \n",
       "4                 0      0                      0                      0   \n",
       "5                 0      1                      0                      0   \n",
       "\n",
       "    EDUCATION_University  MARRIAGE_Divorced  MARRIAGE_Married  \\\n",
       "ID                                                              \n",
       "1                      1                  0                 1   \n",
       "2                      1                  0                 0   \n",
       "3                      1                  0                 0   \n",
       "4                      1                  0                 1   \n",
       "5                      1                  0                 1   \n",
       "\n",
       "    MARRIAGE_Single  default payment next month  \n",
       "ID                                               \n",
       "1                 0                           1  \n",
       "2                 1                           1  \n",
       "3                 1                           0  \n",
       "4                 0                           0  \n",
       "5                 0                           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bokeh \n",
    "import os\n",
    "\n",
    "##Read csv file into dataframe from local directory\n",
    "fname1=(os.path.abspath('Default_new_data.xls'))\n",
    "df=pd.read_excel(fname1,header = 0, index_col=0, na_values=['na','-'])\n",
    "\n",
    "print('Dimension of data is', df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train, (21000, 22)\n",
      "Shape of test, (9000, 22)\n",
      "Proportion of '1's in train : 0.22\n",
      "Proportion of '1's in test : 0.22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train0,test0 = train_test_split(df, test_size=0.3, random_state = 33113, stratify = df['default payment next month'] )\n",
    "\n",
    "#Inspect the shapes\n",
    "print(\"Shape of train,\", train0.shape)\n",
    "print(\"Shape of test,\", test0.shape)\n",
    "\n",
    "#Check that stratify by class works\n",
    "print(\"Proportion of '1's in train : {:.2f}\".format(train0['default payment next month'].value_counts()[1]/train0['default payment next month'].value_counts().sum()))\n",
    "print(\"Proportion of '1's in test : {:.2f}\".format(test0['default payment next month'].value_counts()[1]/test0['default payment next month'].value_counts().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address class imbalance by down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of defaulters in training dataset (4645, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9290, 22)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate out the class labels\n",
    "#Keep all data with defaulters\n",
    "dsdefault_df = train0.loc[train0['default payment next month'] == 1]\n",
    "print(\"Shape of defaulters in training dataset\", dsdefault_df.shape)\n",
    "\n",
    "#Randomly sample 4645 observations from the no default class.\n",
    "dsnodefault_df=train0.loc[train0['default payment next month']==0].sample(n=4645, random_state=33113)\n",
    "\n",
    "dstrain = pd.concat([dsdefault_df,dsnodefault_df])\n",
    "dstrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Train/Test split on the dataset for train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Sept05_BillAmt</th>\n",
       "      <th>Sept05_PayAmt</th>\n",
       "      <th>Aug05_PayAmt</th>\n",
       "      <th>Jul05_PayAmt</th>\n",
       "      <th>Jun05_PayAmt</th>\n",
       "      <th>May05_PayAmt</th>\n",
       "      <th>Apr05_PayAmt</th>\n",
       "      <th>avrg_delay</th>\n",
       "      <th>...</th>\n",
       "      <th>Aug_Pay_Ratio</th>\n",
       "      <th>Missed_payments</th>\n",
       "      <th>SEX_M</th>\n",
       "      <th>EDUCATION_Grad school</th>\n",
       "      <th>EDUCATION_High school</th>\n",
       "      <th>EDUCATION_University</th>\n",
       "      <th>MARRIAGE_Divorced</th>\n",
       "      <th>MARRIAGE_Married</th>\n",
       "      <th>MARRIAGE_Single</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>42</td>\n",
       "      <td>161569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320000</td>\n",
       "      <td>33</td>\n",
       "      <td>1877</td>\n",
       "      <td>4114</td>\n",
       "      <td>4687</td>\n",
       "      <td>3985</td>\n",
       "      <td>22595</td>\n",
       "      <td>4117</td>\n",
       "      <td>5838</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>29</td>\n",
       "      <td>9527</td>\n",
       "      <td>2000</td>\n",
       "      <td>1092</td>\n",
       "      <td>880</td>\n",
       "      <td>990</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000</td>\n",
       "      <td>22</td>\n",
       "      <td>29676</td>\n",
       "      <td>0</td>\n",
       "      <td>1493</td>\n",
       "      <td>803</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130000</td>\n",
       "      <td>49</td>\n",
       "      <td>24008</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>2822</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>6500</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141303</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  AGE  Sept05_BillAmt  Sept05_PayAmt  Aug05_PayAmt  Jul05_PayAmt  \\\n",
       "0     150000   42          161569              0             0             0   \n",
       "1     320000   33            1877           4114          4687          3985   \n",
       "2      50000   29            9527           2000          1092           880   \n",
       "3      30000   22           29676              0          1493           803   \n",
       "4     130000   49           24008           3000          5000          2822   \n",
       "\n",
       "   Jun05_PayAmt  May05_PayAmt  Apr05_PayAmt  avrg_delay  ...  Aug_Pay_Ratio  \\\n",
       "0             0             0            15    5.500000  ...       0.000000   \n",
       "1         22595          4117          5838   -2.000000  ...       1.004885   \n",
       "2           990           780             0   -0.500000  ...       0.201877   \n",
       "3           420             0             0    0.500000  ...       0.000000   \n",
       "4          5000             0          6500   -0.333333  ...       0.141303   \n",
       "\n",
       "   Missed_payments  SEX_M  EDUCATION_Grad school  EDUCATION_High school  \\\n",
       "0                5      1                      1                      0   \n",
       "1                0      1                      1                      0   \n",
       "2                1      1                      0                      1   \n",
       "3                3      0                      0                      0   \n",
       "4                1      1                      0                      0   \n",
       "\n",
       "   EDUCATION_University  MARRIAGE_Divorced  MARRIAGE_Married  MARRIAGE_Single  \\\n",
       "0                     0                  0                 1                0   \n",
       "1                     0                  0                 1                0   \n",
       "2                     0                  0                 1                0   \n",
       "3                     1                  0                 0                1   \n",
       "4                     1                  0                 1                0   \n",
       "\n",
       "   default payment next month  \n",
       "0                           1  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "#shuffle the dataframe to make sure the training data is randomly ordered \n",
    "dstrain = shuffle(dstrain, random_state=33113)\n",
    "\n",
    "dstrain.reset_index(inplace=True)\n",
    "dstrain.drop(['ID'], axis=1 ,inplace= True)\n",
    "\n",
    "X_train=dstrain.iloc[:,:-1]\n",
    "y_train=dstrain['default payment next month']\n",
    "\n",
    "test=test0.reset_index(inplace=False)\n",
    "test.drop(['ID'], axis=1 ,inplace= True)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply preprocessing techniques to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of features \n",
    "features_list=list(X_train.columns)\n",
    "\n",
    "#numerical features\n",
    "nf = features_list[0:13]\n",
    "#categorical features\n",
    "cf = features_list[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('',None)])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, nf),\n",
    "        ('cat', categorical_transformer, cf)], remainder = 'passthrough')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RFE to perform feature selection to check out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV# feature extraction\n",
    "\n",
    "normalized_Xtrain = preprocessor.fit_transform(X_train)\n",
    "\n",
    "logreg=LogisticRegression(penalty = 'l1', random_state=33113, solver='liblinear', max_iter=500)\n",
    "\n",
    "rfecv = RFECV(estimator=logreg, cv=5, scoring='recall')# fit on train set\n",
    "feature_eliminator=rfecv.fit(normalized_Xtrain, y_train)# transform train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 11, 12,  6,  9, 19, 16, 14, 18,  4, 10, 15,  3,  5, 13,  2,  1,\n",
       "        1, 17,  7, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check feature ranking by index\n",
    "feature_eliminator.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features Selected: 2\n",
      "\n",
      "Index of Optimal Features: \n",
      "[16, 17]\n",
      "\n",
      "Feature Names to Retain: \n",
      "['EDUCATION_High school', 'EDUCATION_University']\n"
     ]
    }
   ],
   "source": [
    "def column_index(df, query_cols):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, query_cols, sorter = sidx)]\n",
    "\n",
    "feature_index = []\n",
    "features = []\n",
    "column_index(X_train, X_train.columns.values)\n",
    "\n",
    "for num, i in enumerate(feature_eliminator.support_, start=0):\n",
    "    if i == True:\n",
    "        feature_index.append(num)\n",
    "\n",
    "for num, i in enumerate(X_train.columns.values, start=0):\n",
    "    if num in feature_index:\n",
    "        features.append(X_train.columns.values[num])\n",
    "\n",
    "print(\"Number of Features Selected: {}\\n\".format(feature_eliminator.n_features_))\n",
    "print(\"Index of Optimal Features: \\n{}\\n\".format(feature_index))\n",
    "print(\"Feature Names to Retain: \\n{}\".format(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Optimal number of features : %d\" % feature_eliminator.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax.set_title('Optimal number of features')\n",
    "\n",
    "ax.set_xlabel(\"Number of features selected\")\n",
    "ax.set_ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "ax.plot(range(1, len(feature_eliminator.grid_scores_) + 1), feature_eliminator.grid_scores_)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning with Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score from grid search: 0.6805\n",
      "Best parameters found: {'C': 0.05, 'tol': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Use grid search to find best parameter after Features Elimination\n",
    "#Use only the best ranked optimal features for grid search\n",
    "hyper_grid = GridSearchCV(logreg, param_grid={'C': [0.005, 0.05, 0.5, 0.1, 1, 5, 10, 50, 500, 5000],\n",
    "              'tol' : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]}, scoring='recall', cv=5, iid=False)\n",
    "\n",
    "hyper_grid.fit(normalized_Xtrain[:,16:18], y_train)\n",
    "print(\"Best score from grid search: {0:.4f}\" .format(hyper_grid.best_score_))\n",
    "print(\"Best parameters found: {}\" .format(hyper_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply optimum hyper parameter to model and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Feature Elimination to X_test & standardized (if necessary)\n",
    "X_test = test[features]\n",
    "y_test = test.loc[:,'default payment next month']\n",
    "\n",
    "#Apply tuned hyper parameter to model\n",
    "new_LR_model = LogisticRegression(penalty = 'l2', C=0.05, tol = 1e-06, random_state=33113, solver='sag', max_iter=1000)\n",
    "logistic_model = new_LR_model.fit(normalized_Xtrain[:,16:18],y_train)\n",
    "\n",
    "y_predict=logistic_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1\n",
      "Actual               \n",
      "0          2686  4323\n",
      "1           585  1406\n"
     ]
    }
   ],
   "source": [
    "#Create confusion matrix \n",
    "y_actual=pd.Series(y_test,name=\"Actual\")\n",
    "y_pred=pd.Series(y_predict,name=\"Predicted\")\n",
    "df_confusion = pd.crosstab(y_actual, y_pred)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall/Sensitivity score : 0.7062\n",
      "Accuracy score : 0.4547\n",
      "F1 score : 0.3642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, auc\n",
    "print(\"Recall/Sensitivity score : {:.4f}\".format(recall_score(y_actual, y_pred, average='binary')))\n",
    "print(\"Accuracy score : {:.4f}\".format(accuracy_score(y_actual, y_pred)))\n",
    "print(\"F1 score : {:.4f}\".format(f1_score(y_actual, y_pred, average='binary')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline, an exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(penalty = 'l1', random_state=33113, solver='liblinear', max_iter=500)\n",
    "\n",
    "rfecv1 = RFECV(estimator=logreg, cv=5, scoring='recall')# fit on train set\n",
    "#feature_eliminator=RFECV1.fit(normalized_Xtrain, y_train)# transform train set\n",
    "\n",
    "grid_search = GridSearchCV(logreg, param_grid={'C': [0.005, 0.05, 0.5, 0.1, 1, 5, 10, 50, 500, 5000],\n",
    "              'tol' : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]}, scoring='recall', cv=5, iid=False)\n",
    "\n",
    "MyPipeline= Pipeline(steps=[('preprocess', preprocessor), ('feature_select', rfecv1), ('hyperparam_tuning', grid_search)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the pipeline output for RFECV 'feature_select'\n",
    "X1=MyPipeline.named_steps['preprocess'].transform(X_train)\n",
    "Selector=MyPipeline.named_steps['feature_select'].fit(X1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 11 12  6  9 19 16 14 18  4 10 15  3  5 13  2  1  1 17  7 20]\n"
     ]
    }
   ],
   "source": [
    "#Check out the features ranking by index\n",
    "print(Selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features Selected: 2\n",
      "\n",
      "Index of Optimal Features: \n",
      "[16, 17]\n",
      "\n",
      "Feature Names to Retain: \n",
      "['EDUCATION_High school', 'EDUCATION_University']\n"
     ]
    }
   ],
   "source": [
    "feature_index = []\n",
    "features = []\n",
    "\n",
    "for num, i in enumerate(Selector.support_, start=0):\n",
    "    if i == True:\n",
    "        feature_index.append(num)\n",
    "\n",
    "for num, i in enumerate(X_train.columns.values, start=0):\n",
    "    if num in feature_index:\n",
    "        features.append(X_train.columns.values[num])\n",
    "\n",
    "print(\"Number of Features Selected: {}\\n\".format(Selector.n_features_))\n",
    "print(\"Index of Optimal Features: \\n{}\\n\".format(feature_index))\n",
    "print(\"Feature Names to Retain: \\n{}\".format(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the pipeline on training data\n",
    "Result1 = MyPipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score from grid search: 0.6805\n",
      "Best parameters found: {'C': 0.05, 'tol': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "#Get the best parameter from grid search\n",
    "print(\"Best score from grid search: {0:.4f}\" .format(Result1[2].best_score_))\n",
    "print(\"Best parameters found: {}\" .format(Result1[2].best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Function Pipeline to choose best feature and hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV# feature extraction\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class FeatureSelect_ParamTuning(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, estimator, cv, scoring, parameters):\n",
    "        \"\"\"\n",
    "        A Custom BaseEstimator to eliminate features and get hyperparameter.\n",
    "\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.parameters = parameters\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        rfecv = RFECV(estimator=self.estimator, cv=self.cv, scoring=self.scoring)# fit on train set\n",
    "        grid_search = GridSearchCV(self.estimator, param_grid=self.parameters, scoring=self.scoring, cv=self.cv, iid=False)\n",
    "        X= Pipeline(steps=[('preprocess', preprocessor), ('feature_select', rfecv), ('hyperparam_tuning', grid_search)])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'C': [0.005, 0.05, 0.5, 0.1, 1, 5, 10, 50, 500, 5000],\n",
    "              'tol' : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]}]\n",
    "cv=5\n",
    "scoring = 'recall'\n",
    "model = LogisticRegression(penalty = 'l1', random_state=33113, solver='liblinear', max_iter=200)\n",
    "\n",
    "Optimize1 = FeatureSelect_ParamTuning(estimator=model,cv=cv, scoring=scoring, parameters=parameters)\n",
    "Pipeline1=Optimize1.transform(X_train)\n",
    "Result_logreg= Pipeline1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features Selected: 2\n",
      "\n",
      "Index of Optimal Features: \n",
      "[16, 17]\n",
      "\n",
      "Feature Names to Retain: \n",
      "['EDUCATION_High school', 'EDUCATION_University']\n"
     ]
    }
   ],
   "source": [
    "feature_index = []\n",
    "features = []\n",
    "\n",
    "for num, i in enumerate(Result_logreg[1].support_, start=0):\n",
    "    if i == True:\n",
    "        feature_index.append(num)\n",
    "\n",
    "for num, i in enumerate(X_train.columns.values, start=0):\n",
    "    if num in feature_index:\n",
    "        features.append(X_train.columns.values[num])\n",
    "\n",
    "print(\"Number of Features Selected: {}\\n\".format(Result_logreg[1].n_features_))\n",
    "print(\"Index of Optimal Features: \\n{}\\n\".format(feature_index))\n",
    "print(\"Feature Names to Retain: \\n{}\".format(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score from grid search: 0.6805\n",
      "Best parameters found: {'C': 0.05, 'tol': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "#Get the best parameter from grid search\n",
    "print(\"Best score from grid search: {0:.4f}\" .format(Result_logreg[2].best_score_))\n",
    "print(\"Best parameters found: {}\" .format(Result_logreg[2].best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Function to print params and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetFeaturesnParams():\n",
    "\n",
    "    def __init__(self, X):\n",
    "        \"\"\"\n",
    "        A Custom Function to print out features and best parameters\n",
    "        \"\"\"\n",
    "        X_train= X\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def reveal(self, X, y=None):\n",
    "        feature_index = []\n",
    "        features = []\n",
    "\n",
    "        for num, i in enumerate(self[1].support_, start=0):\n",
    "            if i == True:\n",
    "                feature_index.append(num)\n",
    "\n",
    "        for num, i in enumerate(X_train.columns.values, start=0):\n",
    "            if num in feature_index:\n",
    "                features.append(X_train.columns.values[num])\n",
    "\n",
    "        print(\"Number of Features Selected: {}\\n\".format(self[1].n_features_))\n",
    "        print(\"Index of Optimal Features: \\n{}\\n\".format(feature_index))\n",
    "        print(\"Feature Names to Retain: \\n{}\\n\".format(features))\n",
    "        print(\"Best score from grid search: {0:.4f}\" .format(self[2].best_score_))\n",
    "        print(\"Best parameters found: {}\" .format(self[2].best_params_))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features Selected: 2\n",
      "\n",
      "Index of Optimal Features: \n",
      "[16, 17]\n",
      "\n",
      "Feature Names to Retain: \n",
      "['EDUCATION_High school', 'EDUCATION_University']\n",
      "\n",
      "Best score from grid search: 0.6805\n",
      "Best parameters found: {'C': 0.05, 'tol': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "GetFeaturesnParams.reveal(Result_logreg,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Feature Elimination to X_test & standardized (if necessary)\n",
    "X_test = test[features]\n",
    "y_test = test.loc[:,'default payment next month']\n",
    "\n",
    "normalized_Xtrain = preprocessor.fit_transform(X_train)\n",
    "new_Xtrain = normalized_Xtrain[:,feature_index]\n",
    "\n",
    "#print(X_test.head(5))\n",
    "#Apply tuned hyper parameter to model\n",
    "new_LR_model = LogisticRegression(penalty = 'l1', C=0.05, tol = 1e-06, random_state=33113, solver='liblinear', max_iter=500)\n",
    "logistic_model = new_LR_model.fit(new_Xtrain,y_train)\n",
    "\n",
    "y_predict=logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     0     1\n",
      "Actual               \n",
      "0          2686  4323\n",
      "1           585  1406\n"
     ]
    }
   ],
   "source": [
    "#Create confusion matrix \n",
    "y_actual=pd.Series(y_test,name=\"Actual\")\n",
    "y_pred=pd.Series(y_predict,name=\"Predicted\")\n",
    "df_confusion = pd.crosstab(y_actual, y_pred)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately unable to perform RFE on certain algorithms without the attribute .coef_ or .feature_importance. Let's see the important feature by ranking from the RFE results in Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 8 Features from RFE: \n",
      "['Sept05_PayAmt', 'avrg_delay', 'Aug_Pay_Ratio', 'Missed_payments', 'EDUCATION_Grad school', 'EDUCATION_High school', 'EDUCATION_University', 'MARRIAGE_Married']\n"
     ]
    }
   ],
   "source": [
    "top_8_index = np.argsort(Selector.ranking_)[0:8]\n",
    "\n",
    "top_8_features=[]\n",
    "\n",
    "for num, i in enumerate(X_train.columns.values, start=0):\n",
    "    if num in top_8_index:\n",
    "        #print(i)\n",
    "        top_8_features.append(i)\n",
    "\n",
    "print(\"Top 8 Features from RFE: \\n{}\".format(top_8_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove RFE from Pipeline & rewrite function to choose and hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class HyperParamTuning(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, num_features, cat_features, estimator, cv, scoring, parameters):\n",
    "        \"\"\"\n",
    "        A Custom BaseEstimator to eliminate features and get hyperparameter.\n",
    "\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.cv=cv\n",
    "        self.scoring = scoring\n",
    "        self.parameters = parameters\n",
    "        #numerical features\n",
    "        self.nf = num_features\n",
    "        #categorical features\n",
    "        self.cf = cat_features\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "        categorical_transformer = Pipeline(steps=[('',None)])\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, self.nf),\n",
    "        ('cat', categorical_transformer, self.cf)], remainder = 'passthrough')\n",
    "        grid_search = GridSearchCV(self.estimator, param_grid=self.parameters, scoring=self.scoring, cv=self.cv, iid=False)\n",
    "        X= Pipeline(steps=[('preprocess', preprocessor), ('hyperparam_tuning', grid_search)])\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'C': [0.005, 0.05, 0.5, 0.1, 1, 5, 10, 50, 500, 5000],\n",
    "              'tol' : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]}]\n",
    "cv=5\n",
    "scoring = 'recall'\n",
    "model = LogisticRegression(penalty = 'l1', random_state=33113, solver='liblinear', max_iter=200)\n",
    "\n",
    "Optimize2 = HyperParamTuning(num_features=nf,cat_features=cf,estimator=model,cv=cv, scoring=scoring, parameters=parameters)\n",
    "Pipeline2=Optimize2.transform(X_train)\n",
    "Result_logreg= Pipeline2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score from grid search: 0.6691\n",
      "Best parameters found: {'C': 0.005, 'tol': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Get the best parameter from grid search\n",
    "print(\"Best score from grid search: {0:.4f}\" .format(Result_logreg[1].best_score_))\n",
    "print(\"Best parameters found: {}\" .format(Result_logreg[1].best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_check_is_fitted', '_estimator_type', '_format_results', '_get_param_names', '_get_tags', '_required_parameters', '_run_search', 'best_estimator_', 'best_index_', 'best_params_', 'best_score_', 'classes_', 'cv', 'cv_results_', 'decision_function', 'error_score', 'estimator', 'fit', 'get_params', 'iid', 'inverse_transform', 'multimetric_', 'n_jobs', 'n_splits_', 'param_grid', 'pre_dispatch', 'predict', 'predict_log_proba', 'predict_proba', 'refit', 'refit_time_', 'return_train_score', 'score', 'scorer_', 'scoring', 'set_params', 'transform', 'verbose']\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=33113, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(dir(Result_logreg[1]))\n",
    "print(Result_logreg[1].estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All set to go : Let's start again, this time, filter X_train by best 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9290, 8)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Xtrain = X_train.iloc[:,top_8_index]\n",
    "#new_Xtrain.head(5)\n",
    "new_Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Feature eliminated num_Features and cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "FE_cf = list(new_Xtrain.columns.values[i] for i in [0,1,2,7])\n",
    "FE_nf = [x for x in new_Xtrain.columns.values if x not in FE_cf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical features\n",
    "nf = FE_nf\n",
    "#categorical features\n",
    "cf = FE_cf\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, nf),\n",
    "        ('cat', categorical_transformer, cf)], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EDUCATION_University  EDUCATION_High school  EDUCATION_Grad school  \\\n",
      "0                     0                      0                      1   \n",
      "1                     0                      0                      1   \n",
      "2                     0                      1                      0   \n",
      "3                     1                      0                      0   \n",
      "4                     1                      0                      0   \n",
      "\n",
      "   Aug_Pay_Ratio  avrg_delay  Missed_payments  Sept05_PayAmt  MARRIAGE_Married  \n",
      "0       0.000000    5.500000                5              0                 1  \n",
      "1       1.004885   -2.000000                0           4114                 1  \n",
      "2       0.201877   -0.500000                1           2000                 1  \n",
      "3       0.000000    0.500000                3              0                 0  \n",
      "4       0.141303   -0.333333                1           3000                 1  \n",
      "(9000, 8)\n"
     ]
    }
   ],
   "source": [
    "X_test=test.iloc[:,:-1]\n",
    "y_test=test['default payment next month']\n",
    "new_Xtest = X_test.iloc[:,top_8_index]\n",
    "\n",
    "print(new_Xtest.head(5))\n",
    "\n",
    "normalized_new_Xtrain = preprocessor.fit_transform(new_Xtrain)\n",
    "\n",
    "new_Xtrain_transformer= preprocessor.fit(new_Xtrain)\n",
    "\n",
    "normalized_new_Xtest = new_Xtrain_transformer.transform(X_test)\n",
    "#y_actual=pd.Series(y_test,name=\"Actual\")\n",
    "\n",
    "print(normalized_new_Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to the list of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(penalty = 'l1', random_state=33113, solver='liblinear', max_iter=500),\n",
    "    KNeighborsClassifier(algorithm = 'brute', metric = 'euclidean'),\n",
    "    DecisionTreeClassifier(max_depth=5,random_state=33113),\n",
    "    RandomForestClassifier(max_depth=5, max_features=None,random_state=33113),\n",
    "    AdaBoostClassifier(random_state=33113),\n",
    "    GradientBoostingClassifier(max_features = None,random_state=33113),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel=\"linear\", random_state=31133),\n",
    "    SVC(kernel='rbf', random_state= 31133),\n",
    "    SGDClassifier(penalty = 'elasticnet', l1_ratio=0, learning_rate='adaptive', eta0 = 0.2),\n",
    "    MLPClassifier(activation = 'relu', solver='adam', learning_rate='adaptive', max_iter=1000)\n",
    "]\n",
    "\n",
    "param1 = [{'C': [0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 30, 50],\n",
    "           'tol' : [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}]\n",
    "\n",
    "param2 = [{'n_neighbors': [3,5,7,9,11]}]\n",
    "\n",
    "param3 = [{'min_samples_leaf': [70,80,90,100,110,120]}]\n",
    "\n",
    "param4 = [{'n_estimators': [10,25,50,100,200],\n",
    "           'min_samples_leaf': [1500,1600,1700,1800,1900,2000]}]\n",
    "\n",
    "param5 = [{'n_estimators': [150,175,200,225,250,],\n",
    "           'learning_rate': [0.5,0.8,1.0,1.2,1.5,2.0]}]\n",
    "\n",
    "param6 = [{'n_estimators': [8,9,10,11,12,20,50,100,150],\n",
    "           'learning_rate': [1.0,3.0,4.0,5.0,6.0,7.0,9.0],\n",
    "           'min_samples_leaf': [1700,1800,1900,2000,2100,2200,2300]}]\n",
    "\n",
    "param7 = [{'var_smoothing': [1e-18,1e-17,1e-16, 1e-15, 1e-13]}]\n",
    "\n",
    "param8 = [{'C': [0.0001,0.001,0.01,0.1,0.5,1.0,2.0,5.0],\n",
    "          'tol':[0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0]}]\n",
    "\n",
    "param9 = [{'C': [0.0001,0.001,0.01,0.1,0.5,1.0],\n",
    "          'tol':[0.001, 0.01, 0.1, 0.5, 1.0, 2.0],\n",
    "          'gamma':[0.5,1.0,2.0,3.0]}]\n",
    "\n",
    "param10 = [{'alpha': [1, 5, 8, 9, 10, 11, 12, 13, 15],\n",
    "           'tol': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5]}]\n",
    "\n",
    "param11 = [{'alpha': [1, 10, 40, 50, 55, 60, 70],\n",
    "           'tol': [1e-08, 1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 0.1]}]\n",
    "\n",
    "allparams = [param1, param2, param3, param4, param5, param6, param7, param8, param9, param10, param11]\n",
    "#allparams = [param11]\n",
    "\n",
    "cv=5\n",
    "scoring = 'recall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=33113, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=33113, splitter='best')\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=33113,\n",
      "                       verbose=0, warm_start=False)\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=33113)\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=33113, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=31133,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=31133,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.2, fit_intercept=True,\n",
      "              l1_ratio=0, learning_rate='adaptive', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "\n",
    "for num,clf in enumerate(classifiers):\n",
    "    print(classifiers[num])\n",
    "    Optimize = HyperParamTuning(num_features=FE_nf,cat_features=FE_cf,estimator=clf,cv=cv, scoring=scoring, parameters=allparams[num])\n",
    "    OptPipeline =Optimize.transform(new_Xtrain)\n",
    "    optim_results= OptPipeline.fit(new_Xtrain,y_train)\n",
    "    results.append(optim_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=33113, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n",
      "Best score from grid search: 0.6099\n",
      "Best parameters found: {'C': 5, 'tol': 0.5}\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Best score from grid search: 0.6452\n",
      "Best parameters found: {'n_neighbors': 9}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=33113, splitter='best')\n",
      "Best score from grid search: 0.6316\n",
      "Best parameters found: {'min_samples_leaf': 120}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=33113,\n",
      "                       verbose=0, warm_start=False)\n",
      "Best score from grid search: 0.6790\n",
      "Best parameters found: {'min_samples_leaf': 1700, 'n_estimators': 10}\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=33113)\n",
      "Best score from grid search: 0.6250\n",
      "Best parameters found: {'learning_rate': 1.2, 'n_estimators': 150}\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=33113, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Best score from grid search: 1.0000\n",
      "Best parameters found: {'learning_rate': 5.0, 'min_samples_leaf': 1700, 'n_estimators': 8}\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Best score from grid search: 0.8975\n",
      "Best parameters found: {'var_smoothing': 1e-18}\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=31133,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Best score from grid search: 1.0000\n",
      "Best parameters found: {'C': 0.0001, 'tol': 5.0}\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=31133,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Best score from grid search: 0.8026\n",
      "Best parameters found: {'C': 0.0001, 'gamma': 3.0, 'tol': 0.001}\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.2, fit_intercept=True,\n",
      "              l1_ratio=0, learning_rate='adaptive', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best score from grid search: 0.8654\n",
      "Best parameters found: {'alpha': 8, 'tol': 0.2}\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "Best score from grid search: 1.0000\n",
      "Best parameters found: {'alpha': 50, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Get the best parameter from grid search\n",
    "for n,item in enumerate(results):\n",
    "    print(classifiers[n])\n",
    "    print(\"Best score from grid search: {0:.4f}\" .format(results[n][1].best_score_))\n",
    "    print(\"Best parameters found: {}\" .format(results[n][1].best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Recall/Sensitivity score : 0.5952\n",
      "Accuracy score : 0.7143\n",
      "F1 score : 0.4797\n",
      "KNeighborsClassifier\n",
      "Recall/Sensitivity score : 0.6524\n",
      "Accuracy score : 0.6878\n",
      "F1 score : 0.4804\n",
      "DecisionTreeClassifier\n",
      "Recall/Sensitivity score : 0.6524\n",
      "Accuracy score : 0.7191\n",
      "F1 score : 0.5068\n",
      "RandomForestClassifier\n",
      "Recall/Sensitivity score : 0.5239\n",
      "Accuracy score : 0.7720\n",
      "F1 score : 0.5041\n",
      "AdaBoostClassifier\n",
      "Recall/Sensitivity score : 0.6173\n",
      "Accuracy score : 0.7441\n",
      "F1 score : 0.5163\n",
      "GradientBoostingClassifier\n",
      "Recall/Sensitivity score : 0.7921\n",
      "Accuracy score : 0.3392\n",
      "F1 score : 0.3466\n",
      "GaussianNB\n",
      "Recall/Sensitivity score : 0.9809\n",
      "Accuracy score : 0.2610\n",
      "F1 score : 0.3700\n",
      "SVC\n",
      "Recall/Sensitivity score : 1.0000\n",
      "Accuracy score : 0.2212\n",
      "F1 score : 0.3623\n",
      "SVC\n",
      "Recall/Sensitivity score : 0.8001\n",
      "Accuracy score : 0.4742\n",
      "F1 score : 0.4024\n",
      "SGDClassifier\n",
      "Recall/Sensitivity score : 0.9995\n",
      "Accuracy score : 0.2221\n",
      "F1 score : 0.3624\n",
      "MLPClassifier\n",
      "Recall/Sensitivity score : 1.0000\n",
      "Accuracy score : 0.2212\n",
      "F1 score : 0.3623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, auc\n",
    "#Apply the optimum hyper parameter into the model\n",
    "#Loop through the classifiers and get the scores\n",
    "classifiers = [\n",
    "    LogisticRegression(penalty = 'l1', tol = 0.5, C = 5, random_state=33113, solver='liblinear', max_iter=500),\n",
    "    KNeighborsClassifier(n_neighbors = 9, algorithm = 'brute', metric = 'euclidean'),\n",
    "    DecisionTreeClassifier(min_samples_leaf = 120, max_depth=5),\n",
    "    RandomForestClassifier(n_estimators = 10, min_samples_leaf = 1700, max_depth=5, max_features=None),\n",
    "    AdaBoostClassifier(n_estimators =150, learning_rate = 1.2),\n",
    "    GradientBoostingClassifier(n_estimators=8, learning_rate = 5.0, min_samples_leaf=1700),\n",
    "    GaussianNB(var_smoothing = 1e-18),\n",
    "    SVC(kernel=\"linear\",C=0.0001, tol= 5.0, random_state=31133),\n",
    "    SVC(kernel='rbf', C=0.001, tol= 0.001, gamma=3.0, random_state= 31133),\n",
    "    SGDClassifier(penalty = 'elasticnet', alpha= 8, tol=0.2,l1_ratio=0, learning_rate='adaptive', eta0 = 0.2),\n",
    "    MLPClassifier(activation = 'relu', solver='adam', alpha=70, tol=0.01, learning_rate='adaptive', max_iter=1000)\n",
    "]\n",
    "\n",
    "clf_list=[]\n",
    "recallscores=[]\n",
    "\n",
    "for clf in classifiers:\n",
    "#Apply tuned hyper parameter to model\n",
    "    algo_name = str(clf)\n",
    "    a= algo_name.find(\"(\")\n",
    "    print(algo_name[:a])\n",
    "    clf_list.append(algo_name[:a])\n",
    "    model = clf.fit(normalized_new_Xtrain,y_train)\n",
    "    y_predict=model.predict(normalized_new_Xtest)\n",
    "    y_pred=pd.Series(y_predict,name=\"Predicted\")\n",
    "    recallscores.append(recall_score(y_actual, y_pred, average='binary'))\n",
    "    print(\"Recall/Sensitivity score : {:.4f}\".format(recall_score(y_actual, y_pred, average='binary')))\n",
    "    print(\"Accuracy score : {:.4f}\".format(accuracy_score(y_actual, y_pred)))\n",
    "    print(\"F1 score : {:.4f}\".format(f1_score(y_actual, y_pred, average='binary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'classifiers': clf_list, 'recall_scores': recallscores})\n",
    "clf_name_dict = {'KNeighborsClassifier':'KNN', 'DecisionTreeClassifier': 'DecisionTree', 'RandomForestClassifier': 'RandomForest',\n",
    "                'AdaBoostClassifier':'AdaBoost', 'GradientBoostingClassifier': 'GradientBoost','SGDClassifier': 'SGD',\n",
    "                'MLPClassifier':'MultiLayerPerceptron'}\n",
    "\n",
    "clf_scores=df.replace({'classifiers': clf_name_dict }, inplace = False)\n",
    "clf_scores.iloc[7,0]='SVCLinear'\n",
    "clf_scores.iloc[8,0]='SVCRBF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_scores.sort_values(by=['recall_scores'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", rc={'figure.figsize':(8,5)})\n",
    "\n",
    "mypalette=sns.diverging_palette(250, 385, s=75, n=11)\n",
    "\n",
    "ax = sns.barplot(x=\"recall_scores\", y=\"classifiers\", data=clf_scores, palette=mypalette)\n",
    "\n",
    "ax.set_title(\"Bar Chart of Classifiers Recall Scores on Test Data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed from the plot above, 3 algorithm with the highest sensitivity/recall are SGDClassfier, Linear SVC classfier, and Neural-Network MultiLayerPerceptron. Gaussian NB has a 98% accuracy on the test data. Random Forest have a 67.9% recall score on the training set but is only 52.4% on the test set. This means that random forest is overfitting on the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
